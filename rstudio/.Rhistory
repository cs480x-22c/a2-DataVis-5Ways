Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((131 + 20 + 93)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
library(randomForest)
model <- randomForest(taste ~ . - quality, data = train, mtry = 6)
model
library(stringr)
Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((130 + 20 + 93)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
library(stringr)
Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((129 + 21 + 93)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
set.seed(45)
samp <- sample(nrow(wine), 0.8 * nrow(wine))
train <- wine[samp, ]
test <- wine[-samp, ]
library(randomForest)
model <- randomForest(taste ~ . - quality, data = train, mtry = 6)
model
library(stringr)
Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((129 + 21 + 93)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
set.seed(965)
samp <- sample(nrow(wine), 0.8 * nrow(wine))
train <- wine[samp, ]
test <- wine[-samp, ]
library(randomForest)
model <- randomForest(taste ~ . - quality, data = train, mtry = 6)
model
library(stringr)
Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((129 + 21 + 93)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
library(stringr)
Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((139 + 24 + 69)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
set.seed(965)
samp <- sample(nrow(wine), 0.7 * nrow(wine))
train <- wine[samp, ]
test <- wine[-samp, ]
library(randomForest)
model <- randomForest(taste ~ . - quality, data = train, mtry = 6)
model
library(stringr)
Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((139 + 24 + 69)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
library(stringr)
Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((203 + 33 + 112)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
library(randomForest)
model <- randomForest(taste ~ . - quality, data = train, mtry = 3, ntree = 500)
model
library(stringr)
Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((203 + 33 + 112)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
wine$taste <- ifelse(wine$quality < 5, 'Bad Wines', 'Normal Wines')
wine$taste[wine$quality > 6] <- 'Normal Wines'
wine$taste <- as.factor(wine$taste)
table(wine$taste)
wine$taste <- ifelse(wine$quality < 5, 'Bad Wines', 'Normal Wines')
wine$taste[wine$quality > 6] <- 'Good Wines'
wine$taste <- as.factor(wine$taste)
table(wine$taste)
set.seed(965)
samp <- sample(nrow(wine), 0.7 * nrow(wine))
train <- wine[samp, ]
test <- wine[-samp, ]
library(randomForest)
model <- randomForest(taste ~ . - quality, data = train, mtry = 3, ntree = 500)
model
library(stringr)
Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((203 + 33 + 112)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
library(stringr)
Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((1 + 30 + 395)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
imp <- importance(model)
imp
varImportance <- data.frame(Variables = row.names(imp), Importance = round(imp[,'MeanDecreaseGini'], 2))
rankImportance <- varImportance %>% mutate(Rank = paste0('#', dense_rank(desc(Importance))))
plt <- ggplot(rankImportance, aes(y = Importance, x = reorder(Variables, -Importance), fill = Importance)) +
geom_bar(stat = 'identity') +
scale_fill_gradient(low='#D7CCC8FF', high='#908269FF') +
labs(x="Parameter")+
theme_classic() +
theme(axis.text.x = element_text(angle = 30, vjust = 0.6))
plot(plt)
set.seed(965)
samp <- sample(nrow(wine), 0.75 * nrow(wine))
train <- wine[samp, ]
test <- wine[-samp, ]
library(randomForest)
model <- randomForest(taste ~ . - quality, data = train, mtry = 3, ntree = 500)
model
library(stringr)
Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((1 + 30 + 395)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
library(stringr)
Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((1 + 25 + 329)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
set.seed(123)
samp <- sample(nrow(wine), 0.75 * nrow(wine))
train <- wine[samp, ]
test <- wine[-samp, ]
library(randomForest)
model <- randomForest(taste ~ . - quality, data = train, mtry = 3, ntree = 500)
model
library(stringr)
Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((1 + 25 + 329)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
library(stringr)
Predictions <- predict(model, newdata = test)
table(Predictions, test$taste)
accuracyRate <- ((0 + 24 + 336)/nrow(test)) * 100
str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
imp <- importance(model)
imp
varImportance <- data.frame(Variables = row.names(imp), Importance = round(imp[,'MeanDecreaseGini'], 2))
rankImportance <- varImportance %>% mutate(Rank = paste0('#', dense_rank(desc(Importance))))
plt <- ggplot(rankImportance, aes(y = Importance, x = reorder(Variables, -Importance), fill = Importance)) +
geom_bar(stat = 'identity') +
scale_fill_gradient(low='#D7CCC8FF', high='#908269FF') +
labs(x="Parameter")+
theme_classic() +
theme(axis.text.x = element_text(angle = 30, vjust = 0.6))
plot(plt)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(ggthemes)
library(GGally)
library(caret)
library(MASS)
library(class)
library(corrplot)
library(dplyr)
library(randomForest)
library(gridExtra)
library(car)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(ggthemes)
library(GGally)
library(caret)
library(MASS)
library(class)
library(corrplot)
library(dplyr)
library(randomForest)
library(gridExtra)
library(boot)
library(DAAG)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(ggthemes)
library(GGally)
library(caret)
library(MASS)
library(class)
library(corrplot)
library(dplyr)
library(randomForest)
library(gridExtra)
library(boot)
library(ggResidpanel)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(ggthemes)
library(GGally)
library(caret)
library(MASS)
library(class)
library(corrplot)
library(dplyr)
library(randomForest)
library(gridExtra)
library(boot)
library(nnet)
library(e1071)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(ggthemes)
library(GGally)
library(caret)
library(MASS)
library(class)
library(corrplot)
library(dplyr)
library(randomForest)
library(gridExtra)
library(boot)
library(nnet)
library(e1071)
wine <- na.omit(read.csv("winequality-red.csv", na.strings = "?", stringsAsFactors = TRUE))
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(ggthemes)
library(GGally)
library(caret)
library(MASS)
library(class)
library(corrplot)
library(dplyr)
library(randomForest)
library(gridExtra)
library(boot)
library(nnet)
library(e1071)
wine <- na.omit(read.csv("winequality-red.csv", na.strings = "?", stringsAsFactors = TRUE))
str(wine)
summary(wine)
ggplot(data=wine, aes(quality)) +
geom_histogram(breaks= seq(2, 8, by=1)) +
labs(title="Histogram of wine quality")
wine <- na.omit(read.csv("winequality-red.csv", na.strings = "?", stringsAsFactors = TRUE))
str(wine)
summary(wine)
ggplot(data=wine, aes(wine$quality)) +
geom_histogram(breaks= seq(2, 8, by=1)) +
labs(title="Histogram of wine quality")
corrplot(cor(wine))
ggplot(data=wine, aes(wine)) +
geom_histogram(breaks= seq(2, 8, by=1)) +
labs(title="Histogram of wine quality")
set.seed(1)
train <- sample(dim(wine)[1], dim(wine)[1]*0.8)
test <- wine[-train,]
train <- wine[train,]
fit <- lm('quality ~ volatile.acidity+chlorides+free.sulfur.dioxide+total.sulfur.dioxide+pH+sulphates+alcohol', data=train)
lin.preds <- predict(fit, newdata=test)
hist(fit$residuals, breaks = 30)
ggplot(data=wine, aes(wine)) +
geom_histogram(breaks= seq(2, 8, by=1)) +
labs(title="Histogram of wine quality")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(ggthemes)
library(GGally)
library(caret)
library(MASS)
library(class)
library(corrplot)
library(dplyr)
library(randomForest)
library(gridExtra)
library(boot)
library(nnet)
library(e1071)
wine <- na.omit(read.csv("winequality-red.csv", na.strings = "?", stringsAsFactors = TRUE))
str(wine)
summary(wine)
ggplot(data=wine, aes(wine)) +
geom_histogram(breaks= seq(2, 8, by=1)) +
labs(title="Histogram of wine quality")
ggplot(data=wine, aes(quality)) +
geom_histogram(breaks= seq(2, 8, by=1)) +
labs(title="Histogram of wine quality")
ggplot(wine, aes(y=quality)) +
geom_histogram(breaks= seq(2, 8, by=1)) +
labs(title="Histogram of wine quality")
ggplot(data=wine, aes(quality)) +
geom_histogram(breaks= seq(2, 8, by=1)) +
labs(title="Histogram of wine quality")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(ggthemes)
library(GGally)
library(caret)
library(MASS)
library(class)
library(corrplot)
library(dplyr)
library(randomForest)
library(gridExtra)
library(boot)
library(nnet)
library(e1071)
wine <- na.omit(read.csv("winequality-red.csv", na.strings = "?", stringsAsFactors = TRUE))
str(wine)
summary(wine)
ggplot(data=wine, aes(quality)) +
geom_histogram(breaks= seq(2, 8, by=1)) +
labs(title="Histogram of wine quality")
corrplot(cor(wine))
set.seed(1)
train <- sample(dim(wine)[1], dim(wine)[1]*0.8)
test <- wine[-train,]
train <- wine[train,]
fit <- lm('quality ~ volatile.acidity+chlorides+free.sulfur.dioxide+total.sulfur.dioxide+pH+sulphates+alcohol', data=train)
summary(fit)
lin.preds <- predict(fit, newdata=test)
lin.preds <- round(lin.preds, 0)
# summary(lin.preds)
# summary(as.factor(test$quality))
lin.tbl <- table(test$quality, lin.preds)
lin.tbl
confusionMatrix(lin.tbl)
par(mfrow = c(2,2))
plot(fit)
wine_rem <- wine[-c(833, 1277, 653, 93, 152), ]
fit2 <- lm('quality ~ volatile.acidity+chlorides+free.sulfur.dioxide+total.sulfur.dioxide+pH+sulphates+alcohol', data = wine_rem)
summary(fit2)
lin.preds <- predict(fit2, newdata=test)
wine$quality_dummy <- ifelse(wine$quality < 5, "Bad", ifelse(wine$quality < 7, "Okay", "Good"))
wine$quality_dummy <- as.factor(wine$quality_dummy)
wine <- wine[, -c(12)]
summary(wine$quality_dummy)
set.seed(1)
split<- sort(sample(nrow(wine), nrow(wine)*.75))
train<- wine[split,]
summary(train$quality_dummy)
test<- wine[-split,]
summary(test$quality_dummy)
library(scales)
train$quality_dummy <- relevel(train$quality_dummy, ref = 'Bad') # Setting reference level;
fit2 <- multinom('quality_dummy ~ .', data=train)
cat(crayon::bold(paste("Fitted Multinomial Log-linear with training split of: ", 0.75)),"\n")
print(summary(fit2))
train.pred <- predict(fit2, newdata=train, "class")
train.tbl <- table(train$quality_dummy, train.pred)
train.tbl
round((sum(diag(train.tbl))/sum(train.tbl))*100,2)
test.pred <- predict(fit2, newdata=test, "class")
test.tbl <- table(test$quality_dummy, test.pred)
multinom.cm <- confusionMatrix(test.tbl)
multinom.cm
multinom.acc <- multinom.cm$overall[1]
z <- summary(fit2)$coefficients/summary(fit2)$standard.errors
z
p <- (1 - pnorm(abs(z), 0, 1)) * 2
p
fit2 <- multinom('quality_dummy ~ volatile.acidity + density + pH + sulphates + alcohol', data=train)
cat(crayon::bold(paste("Fitted Multinomial Log-linear with training split of: ", 0.75)),"\n")
print(summary(fit2))
train.pred2 <- predict(fit2, newdata=train, "class")
train.tbl2 <- table(train$quality_dummy, train.pred2)
train.tbl2
round((sum(diag(train.tbl2))/sum(train.tbl2))*100,2)
test.pred2 <- predict(fit2, newdata=test, "class")
test.tbl2 <- table(test$quality_dummy, test.pred2)
multinom.cm2 <- confusionMatrix(test.tbl2)
multinom.cm2
multinom.acc2 <- multinom.cm2$overall[1]
set.seed(1)
X=train[, -c(12)]
Y=train[, c(12)]
bestMtry <- tuneRF(x=X, y=Y, mtryStart=3, stepFactor=1.5, improve=1e-5, ntreeTry=500)
rf.best <- randomForest(quality_dummy~., data=train, mtry=bestMtry, ntree=500)
#summary(rf.best)
rf.best.pred = predict(rf.best, newdata=test)
cm.rf = table(rf.best.pred, test$quality_dummy)
cm.rf
cm.rf_stat <- confusionMatrix(cm.rf)
cm.rf_stat
rf.acc <- cm.rf_stat$overall[1]
imp <- importance(rf.best)
varImportance <- data.frame(Variables = row.names(imp), Importance = round(imp[,'MeanDecreaseGini'], 2))
rankImportance <- varImportance %>% mutate(Rank = paste0('#', dense_rank(desc(Importance))))
plt <- ggplot(rankImportance, aes(y = Importance, x = reorder(Variables, -Importance), fill = Importance)) +
geom_bar(stat = 'identity') +
#scale_fill_gradient(low='#D7CCC8FF', high='#908269FF') +
labs(x="Parameter")+
theme_classic() +
theme(axis.text.x = element_text(angle = 30, vjust = 0.6))
plot(plt)
Accuracy <- c(multinom.acc, multinom.acc2, rf.acc)
Models <- c("Multinomial", "Multinomial (Tuned)", "Random Forest")
Accuracy <- data.frame(Models, Accuracy)
ggplot(data=Accuracy, aes(x= reorder(Models, Accuracy), y= Accuracy, fill= Models)) +
geom_bar(stat= "identity") +
coord_cartesian(ylim= c(.75, 1.00)) +
geom_text(aes(label=percent(Accuracy), vjust= -0.3, size= 3.5)) + guides(size= FALSE) +
xlab("Model") +
ggtitle("Accuracy Comparison") +
theme_classic()
set.seed(1)
X=train[, -c(12)]
Y=train[, c(12)]
bestMtry <- tuneRF(x=X, y=Y, mtryStart=3, stepFactor=1.5, improve=1e-5, ntreeTry=500)
rf.best <- randomForest(quality_dummy~., data=train, mtry=bestMtry, ntree=500)
#summary(rf.best)
rf.best.pred = predict(rf.best, newdata=test)
cm.rf = table(rf.best.pred, test$quality_dummy)
cm.rf
library(stringr)
Predictions <- predict(model, newdata = test)
wine <- read.csv("winequality-red.csv", header = TRUE, sep = ";")
wine <- read.csv("winequality-red.csv", header = TRUE, sep = ";")
wine <- read.csv("winequality-red.csv", header = TRUE, sep = ";")
wine <- read.csv("winequality-red.csv", header = TRUE, sep = ";")
barplot(table(wine$quality), xlab = "Level of Taste", ylab = "Number of Wines")
wine$taste <- ifelse(wine$quality < 5, 'Bad Wines', 'Normal Wines')
wine <- read.csv("winequality-red.csv", header = TRUE, sep = ";")
barplot(table(wine$quality), xlab = "Level of Taste", ylab = "Number of Wines")
wine <- read.csv("winequality-red.csv", header = TRUE, sep = ";")
wine
wine <- read.csv("winequality-red.csv", header = TRUE, sep = ",")
wine
barplot(table(wine$quality), xlab = "Level of Taste", ylab = "Number of Wines")
wine$taste <- ifelse(wine$quality < 5, 'Bad Wines', 'Normal Wines')
wine$taste[wine$quality > 6] <- 'Good Wines'
wine$taste <- as.factor(wine$taste)
table(wine$taste)
set.seed(123)
samp <- sample(nrow(wine), 0.75 * nrow(wine))
train <- wine[samp, ]
test <- wine[-samp, ]
library(randomForest)
model <- randomForest(taste ~ . - quality, data = train, mtry = 3, ntree = 500)
model
imp <- importance(model)
imp
varImportance <- data.frame(Variables = row.names(imp), Importance = round(imp[,'MeanDecreaseGini'], 2))
rankImportance <- varImportance %>% mutate(Rank = paste0('#', dense_rank(desc(Importance))))
plt <- ggplot(rankImportance, aes(y = Importance, x = reorder(Variables, -Importance), fill = Importance)) +
geom_bar(stat = 'identity') +
scale_fill_gradient(low='#D7CCC8FF', high='#908269FF') +
labs(x="Parameter")+
theme_classic() +
theme(axis.text.x = element_text(angle = 30, vjust = 0.6))
plot(plt)
library(stringr)
Predictions <- predict(model, newdata = test)
tbl <- table(Predictions, test$taste)
confusionMatrix(tbl)
#accuracyRate <- ((0 + 24 + 336)/nrow(test)) * 100
#str_interp("Accuracy Rate With 500 Trees: ${accuracyRate}%")
install.packages(tidyverse)
install.packages('tidyverse')
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse)
library('tidyverse')
install.packages('tidyverse')
install.packages("tidyverse")
install.packages("tidyverse")
install.packages('tidyverse')
install.packages('tidyverse')
install.packages('tidyverse')
library('tidyverse')
library('tidyverse')
library(ggplot2)
library(tidyverse)
library(ggplot2)
library(tidyverse)
library(ggplot2)
cars <- read.csv('cars-sample.csv')
library(tidyverse)
library(ggplot2)
cars <- read.csv('cars-sample.csv')
cars
library(tidyverse)
library(ggplot2)
cars <- read.csv('cars-sample.csv')
cars %>% ggplot()
library(tidyverse)
library(ggplot2)
cars <- read.csv('cars-sample.csv')
cars %>% ggplot() +
geom_point(aes(x=Weight, y=MPG))
library(tidyverse)
library(ggplot2)
cars <- read.csv('cars-sample.csv')
cars %>% ggplot() +
geom_point(aes(x=Weight, y=MPG, fill=Manufacturer))
library(tidyverse)
library(ggplot2)
cars <- read.csv('cars-sample.csv')
cars %>% ggplot() +
geom_point(aes(x=Weight, y=MPG, color=Manufacturer))
library(tidyverse)
library(ggplot2)
cars <- read.csv('cars-sample.csv')
cars %>% ggplot() +
geom_point(aes(x=Weight, y=MPG, color=Manufacturer, size=Weight))
library(tidyverse)
library(ggplot2)
cars <- read.csv('cars-sample.csv')
cars %>% ggplot() +
geom_point(aes(x=Weight, y=MPG, color=Manufacturer, size=Weight, opacity=0.5))
library(tidyverse)
library(ggplot2)
cars <- read.csv('cars-sample.csv')
cars %>% ggplot() +
geom_point(aes(x=Weight, y=MPG, color=Manufacturer, size=Weight, alpha=0.5))
